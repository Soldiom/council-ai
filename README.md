# ğŸ›ï¸ VS Code Agent Template â€” Council of Infinite Innovators

A productionâ€‘ready Visual Studio Code setup to build AI solutions backed by the **Council of Infinite Innovators** archetypes (Architect, Engineer, Strategist, etc.).

This template gives you:

* ğŸ§  **Multiâ€‘agent runtime** (LangGraphâ€‘style state machine, simple and robust)
* ğŸ¤– **Agentic AI mode** (ReAct pattern with tool use: web search, code execution, calculations)
* ğŸŒ **Unified AI Platform** (Use ALL HuggingFace models, train YOUR unified model from user interactions!)
* ğŸ” **Forensic AI Agent** (Specialized security analysis: logs, malware, threats â†’ YOUR forensic model!)
*  **Model Ensemble** (Query GPT-4, Claude, Gemini, Llama simultaneously and combine outputs!)
* ğŸ“ **Continuous Learning** (Automatically collect training data and fine-tune YOUR custom models)
* ğŸ”€ **Multiâ€‘model rotation** (12+ premium models, daily rotation per agent)
* ğŸš€ **CLI + API** to run agents locally or serve over HTTP
* ğŸ—ï¸ **Model Builder** (Builds YOUR models from ALL collected data - one command!)
* ğŸ§° **VS Code tasks** (run, test, lint, graphviz render)
* ğŸ§ª **Testing harness** with deterministic "fixtures"
* ğŸ” **.env secrets flow** (no secrets in code)
* ğŸ§© **Prompt packs** for each Council archetype
* ğŸ§± **Dev Container** for clean, reproducible envs
* ğŸ§­ **Roadmap scaffolds** aligned to the 20â€‘Phase framework

---

## 0) Quick Start

**ğŸš€ RECOMMENDED: Free Cloud Deployment (No downloads, no GPU needed!)**

Deploy to Railway, Render, or Fly.io with **FREE Hugging Face Inference API**:

```powershell
# 1) Get a free HF token: https://huggingface.co/settings/tokens
#    (Click "New token" â†’ Read access is enough)

# 2) Deploy to Railway (easiest):
#    - Push this repo to GitHub
#    - Connect at railway.app
#    - Add HF_API_TOKEN secret in Railway dashboard
#    - Deploy! Railway uses railway.toml config automatically

# 3) Or deploy to Render:
#    - Connect GitHub repo at render.com
#    - Create web service from render.yaml
#    - Add HF_API_TOKEN in environment variables
#    - Deploy automatically

# 4) Or deploy to Fly.io:
flyctl launch  # Uses fly.toml config
flyctl secrets set HF_API_TOKEN=hf_your_token_here
flyctl deploy

# Your API will be live at: https://your-app.railway.app (or render/fly URL)
```

**ğŸ’» Local Development (Free API - No Downloads):**

```powershell
# 1) Get free HF token: https://huggingface.co/settings/tokens

# 2) Copy .env.example to .env
cp .env.example .env

# 3) Edit .env and add:
#    HF_API_TOKEN=hf_your_token_here
#    DEFAULT_PROVIDER=hf_inference

# 4) Install and run
pip install -r requirements.txt
python -m cli.app council --agents "strategist,architect" --input "Design a platform"

# 5) View today's model rotation
python -m cli.app models
# Shows which of the 12+ models each agent is using today

# 6) Or start API locally
uvicorn api.main:app --reload
# Visit http://localhost:8000/docs
```

**ï¿½ Multi-Model Rotation** (with HF Pro):

Each agent automatically rotates through 3 preferred models daily:
- **12+ premium models**: Llama 3.2/3.1, Mistral 7B, Qwen 2.5, Gemma 2, Phi 3.5, and more
- **Daily rotation**: Different models for same agent each day (based on day of year % 3)
- **Agent specialization**: Engineer prefers code models, Strategist prefers reasoning models
- **View assignments**: `python -m cli.app models`

See **[MODEL_ROTATION.md](MODEL_ROTATION.md)** for details.

**Free Cloud Models** (via HF Inference API - recommended):
- `meta-llama/Llama-3.2-3B-Instruct` (fast, HF Pro)
- `meta-llama/Llama-3.1-8B-Instruct` (powerful reasoning, HF Pro)
- `mistralai/Mistral-7B-Instruct-v0.3` (excellent instruction following)
- `Qwen/Qwen2.5-7B-Instruct` (multilingual, strong reasoning)
- `google/gemma-2-9b-it` (advanced reasoning)
- `microsoft/Phi-3.5-mini-instruct` (optimized for code)

**ğŸ’¾ Local Models (Optional - Requires Download):**

```powershell
# If you want to run models offline on your machine:
# 1) Set DEFAULT_PROVIDER=huggingface in .env
# 2) Download a model
python scripts/download_model.py microsoft/phi-2
# 3) Run
python -m cli.app run --agent strategist --input "Your prompt"
```

**ğŸ¤– Agentic AI Mode** (NEW - with tool use and iterative reasoning):

```powershell
# Run agent in AGENTIC mode with tools (web search, code execution, calculations)
python -m cli.app agentic --agent strategist --input "Research AI market and calculate growth rate"

# Agent will:
# - Search web for current data
# - Perform calculations  
# - Iterate until task complete
# - Show reasoning trail
```

**Difference:**
- **Simple mode**: One prompt â†’ one response (fast, basic)
- **Agentic mode**: Multi-step reasoning with tools (slower, powerful)

See **[AGENTIC_AI.md](AGENTIC_AI.md)** for full explanation of agentic AI vs simple prompt-based agents.

**ğŸ­ Model Ensemble** (NEW - combine GPT-4, Claude, Gemini, Llama, Qwen):

```powershell
# Query multiple top models and combine their responses intelligently
python -m cli.app ensemble --input "Explain quantum computing" --models 3

# Models used: GPT-4, Claude Opus, Gemini Pro
# Strategy: Best-of-N (highest quality response)
# Result: Better than any single model!

# Check continuous learning progress
python -m cli.app learning-stats

# After collecting 100+ examples, fine-tune YOUR custom model

# OPTION A: OpenAI (quick but vendor lock-in)
python -m cli.app finetune --provider openai

# OPTION B: HuggingFace (YOU OWN THE MODEL!) â­ RECOMMENDED
python -m cli.app finetune --provider huggingface
# See QUICKSTART_OPTION_B.md for Google Colab guide (FREE GPU!)
```

**Benefits:**
- ğŸ† Better quality (ensemble > single model)
- ğŸ“ Continuous learning (auto-collect training data)
- ğŸ’° Cost optimization (95-100% cost reduction with YOUR model)
- ğŸ”§ Full customization (model learns YOUR patterns)
- ğŸ¯ Full ownership (Option B: YOU own the model, run offline, no vendor lock-in)

**Fine-Tuning Guides:**
- **Quick Start:** [QUICKSTART_OPTION_B.md](QUICKSTART_OPTION_B.md) - 3-step process
- **Google Colab (FREE GPU):** [COLAB_FINETUNING.md](COLAB_FINETUNING.md) - Step-by-step
- **Full Guide:** [OPTION_B_HUGGINGFACE.md](OPTION_B_HUGGINGFACE.md) - Complete details
- **Comparison:** [ENSEMBLE_AND_LEARNING.md](ENSEMBLE_AND_LEARNING.md) - All options

**ğŸŒ Unified AI Platform** (NEW - Use ALL HuggingFace Models!):

```powershell
# Discover ALL HuggingFace models (100+ models across 25+ capabilities)
python -m cli.app unified --discover

# Start unified API
uvicorn api.unified:app --reload --port 8000

# Visit: http://localhost:8000/docs
# POST /task with any request â†’ auto-routes to best model!

# Check platform stats
python -m cli.app unified --stats
```

**How it works:**
1. ğŸ” **Discovers ALL HF models** (text, image, audio, translation, etc.)
2. ğŸ¯ **Auto-routes** user requests to best model for task
3. ğŸ“Š **Collects training data** from ALL interactions
4. ğŸ“ **Trains YOUR unified model** daily on collected data
5. ğŸ”„ **Auto-updates** with new HF models and improvements
6. ğŸš€ **Result:** ONE model that does EVERYTHING, gets smarter daily!

**Benefits:**
- âœ… Users interact with your platform â†’ train YOUR model
- âœ… Support 25+ capabilities (translation, summarization, generation, etc.)
- âœ… ONE unified model (vs 100+ separate models)
- âœ… Improves daily from real usage
- âœ… 95% cost reduction after training
- âœ… Auto-discovers new HF models

See **[UNIFIED_PLATFORM.md](UNIFIED_PLATFORM.md)** for complete guide.

**ğŸ” Forensic AI Agent** (NEW - Security & Digital Forensics!):

```powershell
# Analyze security logs
python -m cli.app forensic --input "ERROR: Failed login from 192.168.1.100"

# Analyze malware
python -m cli.app forensic --input "Trojan detected: hash MD5:abc123..."

# Analyze network traffic
python -m cli.app forensic --input "Suspicious connection to 45.33.32.156:4444"

# Auto-extracts IOCs (IPs, hashes, CVEs, URLs)
# Assesses severity (Critical/High/Medium/Low)
# Saves as training data for YOUR forensic model!
```

**ğŸ—ï¸ Build YOUR Models** (NEW - One Command!):

```powershell
# Collects ALL training data from:
# - Ensemble interactions (GPT-4, Claude, Gemini)
# - Platform user data (unified API)
# - Forensic analysis (security logs, malware)

python -m cli.app build

# OR
python scripts/build_unified_model.py

# Output: Ready-to-train datasets for:
# 1. aliAIML/unified-ai-model (general purpose)
# 2. aliAIML/forensic-ai-model (security specialist)
```

**What you get:**
- ğŸŒ **Unified Model** - Handles everything (text, analysis, planning)
- ğŸ” **Forensic Model** - Security expert (logs, malware, threats)
- ğŸ’° **95% cost reduction** - Self-hosted, $0 inference
- ğŸ“ **Continuous learning** - Improves daily from usage
- ğŸ¯ **Complete ownership** - YOUR models, YOUR data

See **[BUILD_NOW.md](BUILD_NOW.md)** for complete guide!

## ğŸ® RTX 4060 + Google Colab Setup

**You have an RTX 4060?** Perfect for fine-tuning!

### **Quick Start (5 minutes):**

```powershell
# 1. Install CUDA PyTorch
pip install torch --index-url https://download.pytorch.org/whl/cu121

# 2. Verify GPU
python -c "import torch; print('GPU:', torch.cuda.get_device_name(0))"

# 3. Run automated fine-tuning
python scripts/auto_local_gpu_finetune.py
```

**What you get:**
- âœ… **RTX 4060**: 2x faster than Colab FREE
- âœ… **Google Colab**: FREE backup when PC is busy
- âœ… **Automated**: Collects data + builds + trains
- âœ… **Cost**: $0.10/day (electricity) vs $50+/month (APIs)

**See:** [LOCAL_GPU_SETUP.md](LOCAL_GPU_SETUP.md) for complete guide

## ğŸ¤– COMPLETE AUTOMATION - NO USER INPUT!

**Everything is automated:**

```powershell
# ONE COMMAND = EVERYTHING AUTOMATED
python scripts/auto_build_and_deploy.py
```

**What gets automated:**
- âœ… **Data Collection**: 35+ training examples across all domains
  - Ensemble queries (GPT-4, Claude, Gemini)
  - Forensic analysis (security logs, malware, threats)
  - Deepfake detection (video, image, audio manipulation)
  - Document forgery (passports, IDs, certificates)
- âœ… **Model Building**: Unified + Forensic + Deepfake + Document models
- âœ… **Dataset Preparation**: Ready-to-train .jsonl files
- âœ… **Google Colab Code**: Copy/paste and run (FREE GPU)
- âœ… **Daily Automation**: Schedule with Task Scheduler
- âœ… **Zero Configuration**: Uses existing API keys automatically

**Cost: $0** (100% free using Google Colab GPU)

See **[BUILD_NOW.md](BUILD_NOW.md)** for complete automation guide!

## Automation

Two automation helpers are included:

- GitHub Actions CI: `.github/workflows/ci.yml` â€” runs lint and tests on push/PR.
- Local runner script: `scripts/auto_run.py` â€” convenience wrapper to run setup, lint and tests or start the API.

Examples:

```powershell
python scripts/auto_run.py setup
python scripts/auto_run.py check
python scripts/auto_run.py api
python scripts/auto_run.py full
```

Note: `pip install -e .` may fail in the repository's flat layout; the script attempts it but does not fail the whole flow if editable install is not possible. Consider converting to a `src/` layout or explicitly listing packages in `pyproject.toml` for a reproducible editable install.
```

---

## Repository Layout

```
ai-council-agent/
â”œâ”€ .devcontainer/
â”‚  â”œâ”€ devcontainer.json
â”‚  â””â”€ Dockerfile
â”œâ”€ .vscode/
â”‚  â”œâ”€ extensions.json
â”‚  â”œâ”€ launch.json
â”‚  â””â”€ tasks.json
â”œâ”€ council/
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ config.py
â”‚  â”œâ”€ graph.py           # LangGraph-style state machine
â”‚  â”œâ”€ memory.py          # simple vector memory + scratchpad
â”‚  â”œâ”€ llm.py             # LLM adapters
â”‚  â”œâ”€ tools/
â”‚  â”‚  â”œâ”€ web.py          # optional web search/citation tool
â”‚  â”‚  â”œâ”€ files.py        # local file read/write safe ops
â”‚  â”‚  â””â”€ code.py         # code runner (sandboxed)
â”‚  â”œâ”€ agents/
â”‚  â”‚  â”œâ”€ base.py
â”‚  â”‚  â”œâ”€ architect.py
â”‚  â”‚  â”œâ”€ entrepreneur.py
â”‚  â”‚  â”œâ”€ strategist.py
â”‚  â”‚  â”œâ”€ engineer.py
â”‚  â”‚  â”œâ”€ designer.py
â”‚  â”‚  â”œâ”€ futurist.py
â”‚  â”‚  â”œâ”€ economist.py
â”‚  â”‚  â”œâ”€ ethicist.py
â”‚  â”‚  â”œâ”€ philosopher.py
â”‚  â”‚  â””â”€ cultural_translator.py
â”‚  â””â”€ prompts/
â”‚     â”œâ”€ system/
â”‚     â”‚  â”œâ”€ meta.txt
â”‚     â”‚  â””â”€ safety.txt
â”‚     â””â”€ archetypes/
â”‚        â”œâ”€ architect.txt
â”‚        â”œâ”€ entrepreneur.txt
â”‚        â”œâ”€ strategist.txt
â”‚        â”œâ”€ engineer.txt
â”‚        â”œâ”€ designer.txt
â”‚        â”œâ”€ futurist.txt
â”‚        â”œâ”€ economist.txt
â”‚        â”œâ”€ ethicist.txt
â”‚        â”œâ”€ philosopher.txt
â”‚        â””â”€ cultural_translator.txt
â”œâ”€ api/
â”‚  â”œâ”€ main.py            # FastAPI server
â”‚  â””â”€ schemas.py
â”œâ”€ cli/
â”‚  â””â”€ app.py             # Typer CLI
â”œâ”€ tests/
â”‚  â”œâ”€ test_agents.py
â”‚  â””â”€ fixtures/
â”‚     â””â”€ strategist_fixture.json
â”œâ”€ plans/                # 20-Phase framework roadmaps
â”‚  â”œâ”€ 01_audit.md
â”‚  â”œâ”€ 04_feature_pipeline.md
â”‚  â”œâ”€ 08_execution_roadmap.md
â”‚  â”œâ”€ 14_resilience_security.md
â”‚  â””â”€ 17_data_analytics.md
â”œâ”€ .env.example
â”œâ”€ .gitignore
â”œâ”€ Makefile
â”œâ”€ pyproject.toml
â”œâ”€ requirements.txt
â”œâ”€ README.md
â””â”€ LICENSE
```

## License

MIT